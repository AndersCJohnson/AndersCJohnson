---
title: "u-sorbed for Changxun"
author: "anders"
date: "2023-05-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Load required libraries

```{r libraries, message=F, cache = FALSE}

library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(kfigr)
library(knitr)
# Packages needed to calculate clr
library(zCompositions)
library(ALDEx2)
library(CoDaSeq)
library(ggrepel)
library(phyloseq)
library(asbio)
library(vegan)
library(gridExtra)
library(tidyverse)
library(ggpubr)
library(agricolae)
library(zinbwave)
library(DESeq2)
library(apeglm)
library(scran)
library(cowplot)
library(VennDiagram)
library(pscl)
library(MASS)
library(dbplyr)
library(gridExtra)
library(grid)



```


# set the color palette. this color palette is useful because its colors are easily distinguishable from one another and prohibits the rainboweffect from happening
```{r set the color palette}
myColors <- c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", "#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", "#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", "#8A7C64", "#599861")
```


##set the working directory
```{r set working directory}
setwd("your/file/path/here")
```


## Read data files

We start by reading in the data files: ASVs (counts), sample data ("metadata") and the taxonomy.

```{r read-counts-data }
# Read the ASV table and turn it long without zeroes
ASVs <- read_csv("U_sorbed_JA_SCH_ASV_table.csv",
  col_types = cols(.default = col_double(), seqid = col_character())) %>%
  gather(sample, count, 2:60) %>%
  # Take away rows with zero count
  filter(count > 0) %>%
  # Take away samples with less than 500 observations (this is an arbitrary choice 
  # to get rid of samples with very low sequencing depth). 
    #due to low seq depth, samples with less than 500 obsv were not filtered
  #group_by(sample) %>% 
  #filter(sum(count) >= 500) %>% 
  ungroup()
```

```{r read the taxonomy data}
# Read the taxonomy table
taxonomy <- read_csv("U_sorbed_JA_SCH_ASV_tax.csv", col_types = cols("seqid" = col_character(), "Domain" = col_character(), "Kingdom"  = col_character(), "Class" = col_character(), "Order" = col_character(), "Family" = col_character(), "Genus" = col_character(), "Species" = col_character(), "confidence" = col_double(), "sequence" = col_character())) %>% 
  # rename "uncultured" to N/A
  mutate(across(c(Class, Order, Family, Genus, Species), ~na_if(., "uncultured"))) %>%
  mutate(across(c(Class, Order, Family, Genus, Species), ~na_if(., "uncultured bacterium"))) %>%
  mutate(across(c(Class, Order, Family, Genus, Species), ~na_if(., "uncultured organism"))) %>%
  mutate(across(c(Class, Order, Family, Genus, Species), ~na_if(., "uncultured Actinomycetales bacterium"))) 
  # Rename Feature ID to seqid, the name in the ASV table
   #rename(seqid = ASV_ID)
```

```{r read the metadata}
# Read the sample data ("metadata")
samples <- read_csv("U_sorbed_JA_SCH_metadata.csv", 
  col_names = TRUE,
  col_types = cols(.default = col_double(),
    sample = col_character(),               
    name = col_character(), 
    test = col_character(),
    coprecipitant = col_character(), 
    number = col_character(),
    new_names = col_character(),
    days = col_character(),
    pH = col_number(),
    Fe2_mgL = col_number(),
    FeTot_mgL = col_number(),
    S_mgL = col_number(),
    U_mgL = col_number(),
    P_mgL = col_number(),
    Ca_mgL = col_number(),
    K_mgL = col_number(),
    Mg_mgL = col_number(),
    Na_mgL = col_number(),
    Si_mgL = col_number())) %>% 
    
  
  # Subset the table to only contain the samples that are in the asvs table (which was 
  # subset to only contain samples > 500 observations).
  semi_join(ASVs, by = 'sample')
# subset to remove rows with NA values
#samples<-samples[complete.cases(samples), ]
```


```{r}
sequencing_depth <- read_csv("U_sorbed_JA_SCH_ASV_table.csv", col_names = TRUE,
  col_types = cols(.default = col_double(), seqid = col_character()))

asvs<-sequencing_depth%>%
  gather(sample, count, 2:ncol(.)) %>% 
  filter(count > 0) %>%
  group_by(sample) %>% 
  mutate(relab = count/sum(count)) %>% 
  filter(n() > 19) %>% 
  ungroup()


sequencing_depth %>%
  gather(sample, count, -1)%>%
  group_by(seqid)%>%
  #filter(count > 0) %>% 
  ungroup() %>%
  mutate(count = as.integer(count))%>%
  # Add metadata
 inner_join(samples, by = 'sample')%>%
  # Relative abundance, grouped first by sample name, and then next by rep(sampling replicate identifier)
  group_by(sample) %>%
  #group_by(site, zone)%>% #do at sample level first 
  mutate(relab = count/sum(count)) %>% ungroup() -> sequencing_depth_seqtab
```


```{r, rarefaction_bacteria}
ASV_counts_USCH <- sequencing_depth_seqtab %>%
  subset(coprecipitant == "USCH") %>%
  dplyr::select (seqid, sample, count) %>%
  spread(seqid, count, fill = 0) %>%
  column_to_rownames("sample")

totals_USCH <- rowSums(ASV_counts_USCH)
totals_df_USCH <-data.frame(sample = rownames(ASV_counts_USCH), Total_ASV_Count = totals_USCH) 
print(totals_df_USCH)

totals_df_USCH<- totals_df_USCH %>%
  merge(samples, by = "sample") %>%
dplyr::select(days, Total_ASV_Count)

totals_df_USCH <- totals_df_USCH %>%
 group_by(days) %>% 
    summarize(
    Mean_ASV_Count = mean(Total_ASV_Count))%>%
      ungroup()%>%
  arrange(fct_relevel(days, c("9", "12", "16", "22", "37", "37C", "40", "83", "180", "180C")))
  
  
pdf("Figures/ASV_totals_df_USCH.pdf", width = 8, height = 8)

grid.table(totals_df_USCH)
dev.off()

ASV_counts_USCH%>%
  rarecurve(sample= 100, step = 100, xlab = "Sequencing Depth", ylab = "# of ASVs")
```

```{r, rarefaction_bacteria}
ASV_counts_UJA_LPH <- sequencing_depth_seqtab %>%
  subset(coprecipitant == "UJA-LPH") %>%
  dplyr::select (seqid, sample, count) %>%
  spread(seqid, count, fill = 0) %>%
  column_to_rownames("sample")
  
totals_UJA_LPH <- rowSums(ASV_counts_UJA_LPH)
totals_df_UJA_LPH <-data.frame(sample = rownames(ASV_counts_UJA_LPH), Total_ASV_Count = totals_UJA_LPH) 
print(totals_df_UJA_LPH)

totals_df_UJA_LPH<- totals_df_UJA_LPH %>%
  merge(samples, by = "sample") %>%
dplyr::select(days, Total_ASV_Count)

totals_df_UJA_LPH <- totals_df_UJA_LPH %>%
 group_by(days) %>% 
    summarize(
    Mean_ASV_Count = mean(Total_ASV_Count))%>%
      ungroup()%>%
  arrange(fct_relevel(days, c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C")))

pdf("Figures/ASV_totals_df_UJA_LPH.pdf", width = 8, height = 8)

grid.table(totals_df_UJA_LPH)
dev.off()
  
ASV_counts_UJA_LPH%>%  
  rarecurve(sample= 100, step = 100, xlab = "Sequencing Depth", ylab = "# of ASVs")
```


#Export the plot
```{r}
### manually save with right-click "save as"
```


###top20 tables

#bacteria


```{r}
# Read in metadata file
samples_USCH <- read_csv("U_sorbed_JA_SCH_metadata.csv",
                         col_names = TRUE,
  col_types = cols(.default = col_double(),
    sample = col_character(),               
    name = col_character(), 
    test = col_character(),
    coprecipitant = col_character(), 
    number = col_character(),
    new_names = col_character(),
    days = col_character(),
    pH = col_number(),
    Fe2_mgL = col_number(),
    FeTot_mgL = col_number(),
    S_mgL = col_number(),
    U_mgL = col_number(),
    P_mgL = col_number(),
    Ca_mgL = col_number(),
    K_mgL = col_number(),
    Mg_mgL = col_number(),
    Na_mgL = col_number(),
    Si_mgL = col_number()))%>%
  subset(coprecipitant == "USCH")


# Read in ASV table
sequencing_depth_USCH <- read_csv("U_sorbed_JA_SCH_ASV_table.csv", 
                                  col_names = TRUE,
                                  col_types = cols(.default = col_double(), 
                                                   seqid = col_character()))

# Identify the column number to subset from sequencing_depth_USCH and remove them 
sequencing_depth_USCH <- sequencing_depth_USCH[ , -c(32:60)]


asvs_USCH<-sequencing_depth_USCH%>%
  gather(sample, count, 2:ncol(.)) %>% 
  filter(count > 0) %>%
  group_by(sample) %>% 
  mutate(relab = count/sum(count)) %>% 
  filter(n() > 19) %>% 
  ungroup()


sequencing_depth_USCH %>%
  gather(sample, count, -1)%>%
  group_by(seqid)%>%
  #filter(count > 0) %>% 
  ungroup() %>%
  mutate(count = as.integer(count))%>%
  # Add metadata
 inner_join(samples_USCH, by = 'sample')%>%
  # Relative abundance, grouped first by sample name, and then next by rep(sampling replicate identifier)
  group_by(sample) %>%
  #group_by(site, zone)%>% #do at sample level first 
  mutate(relab = count/sum(count)) %>% ungroup() -> sequencing_depth_seqtab_USCH


```


```{r}
seqtab_USCH <- sequencing_depth_seqtab_USCH
```



###looks at the top 20 genera, 
```{r, select top 20 most abundant genera all}
# Select the 20 most abundant genera
seqtab_USCH %>%
  inner_join(taxonomy, by = 'seqid')%>%
  group_by(Genus, sample)%>%
  # Calculate the relative abundance of each genus in each sample
  summarise(relab = sum(relab))%>%
  # Calculate the mean relative abundance of each genus over the samples
  summarise(mean_relab = sum(relab))%>%
  ungroup() %>%
  # Filter out non-assigned genera
  filter(!is.na(Genus))%>%
  # Select the top 20
  top_n(20, mean_relab) -> t20_genus_USCH
```
##print the top20 genera table
```{r print top20 genera table}
t20_genus_USCH%>%
 arrange(desc(mean_relab))->U_sorbed_JA_SCH_t20_genus_order_decending_USCH

pdf("Figures/U_sorbed_JA_SCH_USCH_genera_top_20_relab_table.pdf", height=8, width=8)
title <- "Overall, Top 20 Genera, Relative Abundance"

grid::grid.newpage()
grid::grid.text(title,x = (.5), y = (0.9))
grid.table(U_sorbed_JA_SCH_t20_genus_order_decending_USCH) 
dev.off()
```

###looks at the top 20 genera by day, 
```{r, select top 20 by day most abundant genera all}
# Select the 20 most abundant genera
seqtab_USCH %>%
  inner_join(taxonomy, by = 'seqid')%>%
  group_by(Genus, sample)%>%
  # Calculate the relative abundance of each genus in each sample
  summarise(relab = sum(relab))%>%
  # Calculate the mean relative abundance of each genus over the samples
  summarise(mean_relab = sum(relab))%>%
  ungroup() %>%
  # Filter out non-assigned genera
  filter(!is.na(Genus))%>%
  # Select the top 20
  top_n(20, mean_relab) -> t20_genus_days_USCH
```
##print the top20 genera table
```{r print top20 genera table}
t20_genus_days_USCH%>%
 arrange(desc(mean_relab))->U_sorbed_JA_SCH_t20_genus_order_decending_USCH_days

print(t20_genus_days_USCH)

pdf("Figures/U_sorbed_JA_SCH_USCH_genera_top_20_relab_table_days.pdf", height=8, width=8)
title <- "Overall, Top 20 Genera, Relative Abundance, days"

grid::grid.newpage()
grid::grid.text(title,x = (.5), y = (0.9))
grid.table(U_sorbed_JA_SCH_t20_genus_order_decending_USCH_days) 
dev.off()
```







#UJA_LPH

```{r}
# Read in metadata file
samples_UJA_LPH <- read_csv("U_sorbed_JA_SCH_metadata.csv",
                         col_names = TRUE,
  col_types = cols(.default = col_double(),
    sample = col_character(),               
    name = col_character(), 
    test = col_character(),
    coprecipitant = col_character(), 
    number = col_character(),
    new_names = col_character(),
    days = col_character(),
    pH = col_number(),
    Fe2_mgL = col_number(),
    FeTot_mgL = col_number(),
    S_mgL = col_number(),
    U_mgL = col_number(),
    P_mgL = col_number(),
    Ca_mgL = col_number(),
    K_mgL = col_number(),
    Mg_mgL = col_number(),
    Na_mgL = col_number(),
    Si_mgL = col_number()))%>%
  subset(coprecipitant == "UJA-LPH")


# Read in ASV table
sequencing_depth_UJA_LPH <- read_csv("U_sorbed_JA_SCH_ASV_table.csv", 
                                  col_names = TRUE,
                                  col_types = cols(.default = col_double(), 
                                                   seqid = col_character()))

# Identify the column number to subset from sequencing_depth_UJA-LPH and remove them 
sequencing_depth_UJA_LPH <- sequencing_depth_UJA_LPH[ , -c(2:31)]


asvs_UJA_LPH<-sequencing_depth_UJA_LPH%>%
  gather(sample, count, 2:ncol(.)) %>% 
  filter(count > 0) %>%
  group_by(sample) %>% 
  mutate(relab = count/sum(count)) %>% 
  filter(n() > 19) %>% 
  ungroup()


sequencing_depth_UJA_LPH %>%
  gather(sample, count, -1)%>%
  group_by(seqid)%>%
  #filter(count > 0) %>% 
  ungroup() %>%
  mutate(count = as.integer(count))%>%
  # Add metadata
 inner_join(samples_UJA_LPH, by = 'sample')%>%
  # Relative abundance, grouped first by sample name, and then next by rep(sampling replicate identifier)
  group_by(sample) %>%
  #group_by(site, zone)%>% #do at sample level first 
  mutate(relab = count/sum(count)) %>% ungroup() -> sequencing_depth_seqtab_UJA_LPH


```


```{r}
seqtab_UJA_LPH <- sequencing_depth_seqtab_UJA_LPH
```



###looks at the top 20 genera, 
```{r, select top 20 most abundant genera all}
# Select the 20 most abundant genera
seqtab_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid')%>%
  group_by(Genus, sample)%>%
  # Calculate the relative abundance of each genus in each sample
  summarise(relab = sum(relab))%>%
  # Calculate the mean relative abundance of each genus over the samples
  summarise(mean_relab = sum(relab))%>%
  ungroup() %>%
  # Filter out non-assigned genera
  filter(!is.na(Genus))%>%
  # Select the top 20
  top_n(20, mean_relab) -> t20_genus_UJA_LPH
```
##print the top20 genera table
```{r print top20 genera table}
t20_genus_UJA_LPH%>%
 arrange(desc(mean_relab))->U_sorbed_JA_SCH_t20_genus_order_decending_UJA_LPH

pdf("U_sorbed_JA_SCH_UJA-LPH_genera_top_20_relab_table.pdf", height=8, width=8)
title <- "Overall, Top 20 Genera, Relative Abundance"

grid::grid.newpage()
grid::grid.text(title,x = (.5), y = (0.9))
grid.table(U_sorbed_JA_SCH_t20_genus_order_decending_UJA_LPH) 
dev.off()
```






####genera stacked bars  

#Genera
#USCH


```{r assign-top10-genera-to-taxonomy-USCH}
# Start by finding the top 11 genera *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Genus, sample) %>%
  # Calculate the relative abundance of each genera in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each genera over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned genera
  filter(!is.na(Genus)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topgenera
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the genera column, with the old name and as "topgenera"
      transmute(Genus, topgenus = Genus),
    by = 'Genus'
  ) %>%
  # Set topgenus to 'Other' for those that were not among the top 11
  replace_na(list('topgenus' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Genus) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-genus}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(topgenus, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))),
    y = relab, 
    fill = fct_relevel(topgenus, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Genus-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
    
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_genus_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```

```{r}
summary_table_genera_USCH <- asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample") %>%
  group_by(topgenus, days) %>%
  summarise(relab = sum(relab) / 3) %>%
  ungroup()%>%
  pivot_wider(names_from = days, values_from = relab, values_fill = 0) %>%
  dplyr::select(topgenus, "9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C")

# Print the summary table
print(summary_table_genera_USCH)
write.csv(summary_table_genera_USCH, "Figures/summary_table_genera_USCH.csv", row.names = FALSE)
```




#UJA-LPH


```{r assign-top10-genera-to-taxonomy-UJA_LPH}
# Start by finding the top 11 genera *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Genus, sample) %>%
  # Calculate the relative abundance of each genera in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each genera over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned genera
  filter(!is.na(Genus)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topgenera
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the genera column, with the old name and as "topgenera"
      transmute(Genus, topgenus = Genus),
    by = 'Genus'
  ) %>%
  # Set topgenus to 'Other' for those that were not among the top 11
  replace_na(list('topgenus' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Genus) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-genus}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(topgenus, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topgenus, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Genus-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
    theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_genus_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```




##other taxonomic levels 



#Family

#USCH


```{r assign-top10-family-to-taxonomy-USCH}
# Start by finding the top 11 family *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Family, sample) %>%
  # Calculate the relative abundance of each family in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each family over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned family
  filter(!is.na(Family)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topfamily
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the family column, with the old name and as "topfamily"
      transmute(Family, topfamily = Family),
    by = 'Family'
  ) %>%
  # Set topfamily to 'Other' for those that were not among the top 11
  replace_na(list('topfamily' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Family) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-family}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(topfamily, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topfamily, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Family-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
    theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_family_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#UJA-LPH


```{r assign-top10-family-to-taxonomy-UJA_LPH}
# Start by finding the top 11 family *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Family, sample) %>%
  # Calculate the relative abundance of each family in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each family over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned family
  filter(!is.na(Family)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topfamily
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the family column, with the old name and as "topfamily"
      transmute(Family, topfamily = Family),
    by = 'Family'
  ) %>%
  # Set topfamily to 'Other' for those that were not among the top 11
  replace_na(list('topfamily' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Family) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-family}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(topfamily, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topfamily, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Family-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
    theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_family_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```




#Order

#USCH


```{r assign-top10-order-to-taxonomy-USCH}
# Start by finding the top 11 order *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Order, sample) %>%
  # Calculate the relative abundance of each order in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each order over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned order
  filter(!is.na(Order)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column toporder
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the order column, with the old name and as "toporder"
      transmute(Order, toporder = Order),
    by = 'Order'
  ) %>%
  # Set toporder to 'Other' for those that were not among the top 11
  replace_na(list('toporder' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Order) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-order}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(toporder, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(toporder, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Order-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_order_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#UJA-LPH


```{r assign-top10-order-to-taxonomy-UJA_LPH}
# Start by finding the top 11 order *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Order, sample) %>%
  # Calculate the relative abundance of each order in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each order over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned order
  filter(!is.na(Order)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column toporder
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the order column, with the old name and as "toporder"
      transmute(Order, toporder = Order),
    by = 'Order'
  ) %>%
  # Set toporder to 'Other' for those that were not among the top 11
  replace_na(list('toporder' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Order) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-order}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(toporder, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(toporder, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Order-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_order_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```




#Class 

#USCH


```{r assign-top10-class-to-taxonomy-USCH}
# Start by finding the top 11 class *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Class, sample) %>%
  # Calculate the relative abundance of each class in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each class over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned class
  filter(!is.na(Class)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topclass
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the class column, with the old name and as "topclass"
      transmute(Class, topclass = Class),
    by = 'Class'
  ) %>%
  # Set topclass to 'Other' for those that were not among the top 11
  replace_na(list('topclass' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Class) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-class}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(topclass, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topclass, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Class-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
    theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_class_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#UJA-LPH


```{r assign-top10-class-to-taxonomy-UJA_LPH}
# Start by finding the top 11 class *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Class, sample) %>%
  # Calculate the relative abundance of each class in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each class over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned class
  filter(!is.na(Class)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topclass
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the class column, with the old name and as "topclass"
      transmute(Class, topclass = Class),
    by = 'Class'
  ) %>%
  # Set topclass to 'Other' for those that were not among the top 11
  replace_na(list('topclass' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Class) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-class}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(topclass, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topclass, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Class-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
    theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_class_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```





#Phylum, 


#USCH


```{r assign-top10-phyla-to-taxonomy-USCH}
# Start by finding the top 11 phyla *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Phylum, sample) %>%
  # Calculate the relative abundance of each phyla in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each phyla over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned phyla
  filter(!is.na(Phylum)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topphyla
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the phyla column, with the old name and as "topphyla"
      transmute(Phylum, topphylum = Phylum),
    by = 'Phylum'
  ) %>%
  # Set topphylum to 'Other' for those that were not among the top 11
  replace_na(list('topphylum' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Phylum) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-phylum}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(topphylum, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topphylum, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Phylum-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_phylum_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#UJA-LPH


```{r assign-top10-phyla-to-taxonomy-UJA_LPH}
# Start by finding the top 11 phyla *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Phylum, sample) %>%
  # Calculate the relative abundance of each phyla in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each phyla over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned phyla
  filter(!is.na(Phylum)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topphyla
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the phyla column, with the old name and as "topphyla"
      transmute(Phylum, topphylum = Phylum),
    by = 'Phylum'
  ) %>%
  # Set topphylum to 'Other' for those that were not among the top 11
  replace_na(list('topphylum' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Phylum) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-phylum}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(topphylum, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topphylum, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Phylum-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_phylum_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



# Kingdom, 

#USCH


```{r assign-top10-kingdom-to-taxonomy-USCH}
# Start by finding the top 11 kingdom *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Kingdom, sample) %>%
  # Calculate the relative abundance of each kingdom in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each kingdom over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned kingdom
  filter(!is.na(Kingdom)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topkingdom
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the kingdom column, with the old name and as "topkingdom"
      transmute(Kingdom, topkingdom = Kingdom),
    by = 'Kingdom'
  ) %>%
  # Set topkingdom to 'Other' for those that were not among the top 11
  replace_na(list('topkingdom' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Kingdom) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-kingdom}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(topkingdom, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topkingdom, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Kingdom-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_kingdom_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#UJA-LPH


```{r assign-top10-kingdom-to-taxonomy-UJA_LPH}
# Start by finding the top 11 kingdom *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Kingdom, sample) %>%
  # Calculate the relative abundance of each kingdom in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each kingdom over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned kingdom
  filter(!is.na(Kingdom)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topkingdom
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the kingdom column, with the old name and as "topkingdom"
      transmute(Kingdom, topkingdom = Kingdom),
    by = 'Kingdom'
  ) %>%
  # Set topkingdom to 'Other' for those that were not among the top 11
  replace_na(list('topkingdom' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Kingdom) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-kingdom}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(topkingdom, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topkingdom, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Kingdom-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_kingdom_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#Domain 


```{r assign-top10-domain-to-taxonomy-USCH}
# Start by finding the top 11 domain *on average* over the samples
p_USCH <- asvs_USCH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Domain, sample) %>%
  # Calculate the relative abundance of each domain in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each domain over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned domain
  filter(!is.na(Domain)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topdomain
taxonomy_USCH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_USCH %>% 
      # Duplicate the domain column, with the old name and as "topdomain"
      transmute(Domain, topdomain = Domain),
    by = 'Domain'
  ) %>%
  # Set topdomain to 'Other' for those that were not among the top 11
  replace_na(list('topdomain' = 'Other'))
```

```{r}
asvs_USCH %>%
  left_join(taxonomy_USCH, by = 'seqid') %>%
  group_by(sample, Domain) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_USCH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "USCH.1", "USCH.2", etc.)
samples_USCH_grouped <- samples_USCH %>%
    mutate(common_name = gsub("^(USCH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-domain}
asvs_USCH %>%
  inner_join(taxonomy_USCH, by = 'seqid') %>%
  inner_join(samples_USCH_grouped, by = "sample")%>%
  group_by(topdomain, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topdomain, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Domain-USCH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_domain_USCH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```



#UJA-LPH


```{r assign-top10-domain-to-taxonomy-UJA_LPH}
# Start by finding the top 11 domain *on average* over the samples
p_UJA_LPH <- asvs_UJA_LPH %>%
  inner_join(taxonomy, by = 'seqid') %>%
  group_by(Domain, sample) %>%
  # Calculate the relative abundance of each domain in each sample
  summarise(relab = sum(relab)) %>%
  # Calculate the *mean* relative abundance of each domain over the samples
  summarise(mean_relab = sum(relab)) %>%
  ungroup() %>%
  # Filter out non-assigned domain
  filter(!is.na(Domain)) %>%
  # Select the top 11
  top_n(20, mean_relab)
# Add this information to the taxonomy table as the column topdomain
taxonomy_UJA_LPH <- taxonomy %>%
  # Join in the top 10 table. *Important* with left join, otherwise you loose rows in the
  # taxonomy table that do not appear in the top 11 table.
  left_join(
    p_UJA_LPH %>% 
      # Duplicate the domain column, with the old name and as "topdomain"
      transmute(Domain, topdomain = Domain),
    by = 'Domain'
  ) %>%
  # Set topdomain to 'Other' for those that were not among the top 11
  replace_na(list('topdomain' = 'Other'))
```

```{r}
asvs_UJA_LPH %>%
  left_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  group_by(sample, Domain) %>% summarise(relab = sum(relab)) %>% ungroup() %>%
  spread(sample, relab, fill = 0) %>%
  write_csv('asvs_UJA_LPH.tsv')
```
### merging triplicates
```{r}
# Group samples by the first part of their name (i.e., "UJA_LPH.1", "UJA_LPH.2", etc.)
samples_UJA_LPH_grouped <- samples_UJA_LPH %>%
    mutate(common_name = gsub("^(UJA-LPH\\.\\d+)\\..*$", "\\1", name)) %>%
  mutate(common_name = if_else(grepl("\\.C$", name), paste(common_name, "C", sep = ""), common_name))%>%
  group_by(common_name) %>%
  mutate(common_name = gsub("\\.", "", common_name)) %>%
  ungroup()
```


```{r plot-top-domain}
asvs_UJA_LPH %>%
  inner_join(taxonomy_UJA_LPH, by = 'seqid') %>%
  inner_join(samples_UJA_LPH_grouped, by = "sample")%>%
  group_by(topdomain, sample, name, common_name, days) %>% summarise(relab = sum(relab)/3) %>% ungroup() %>%
  ggplot(aes(
    x = fct_relevel(days, rev(c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))), 
    y = relab, 
    fill = fct_relevel(topdomain, "Other" , after = Inf))) +
  geom_col() +
  scale_fill_manual(values = myColors) +
  coord_flip() +
  labs(title = "Top 20 Domain-UJA_LPH_Grouped_triplicates")+
  ylab("Relative Abundance")+
  xlab("Days")+
  theme(
   legend.position = 'bottom', legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
ggsave("figures/U_sorbed_JA_SCH_StackedBar_Top_20_domain_UJA-LPH_triplicates.pdf",scale = 2, width = 20, height = 15, units = "cm")
```









#DIversity indicies and PCA



```{r simple NMDS, USCH}
feature_table_USCH <- read_csv("U_sorbed_JA_SCH_ASV_table.csv",
  col_types = cols(.default = col_double(), seqid = col_character()))
feature_table_USCH <- feature_table_USCH[ , -c(32:60)]

T_otu_mat <- feature_table_USCH %>% tibble::column_to_rownames("seqid") %>% as.matrix() %>% t()


tax_mat <- taxonomy_USCH %>% tibble::column_to_rownames("seqid") %>% as.matrix()

samples_nmds <- samples_USCH_grouped %>% tibble::column_to_rownames("sample")%>% as.matrix()



# Shannon's H' library(vegan)
H<-diversity(T_otu_mat)

# Observed Richness
richness<-specnumber(T_otu_mat)

# Pielou's Evenness
evenness<- H/log(richness)

# Create alpha diversity dataframe including environmental data pH + iron_total + Fe_HCL_soluble + Sulfur_total + S_HCL_Soluble
alpha <- cbind(shannon = H, richness = richness, pielou = evenness, samples_nmds) 


alpha<-data.frame(sample= row.names(alpha), alpha)

head(alpha)

repl_U_sorbed_JA_SCH_USCH.mdf<- T_otu_mat

U_sorbed_JA_SCH_USCH.bray<- vegdist(repl_U_sorbed_JA_SCH_USCH.mdf, method = "bray")

U_sorbed_JA_SCH_USCH.bray

U_sorbed_JA_SCH_USCH.jac <- vegdist(repl_U_sorbed_JA_SCH_USCH.mdf, method = "jaccard" , binary = T)

U_sorbed_JA_SCH_USCH.jac

###PCOA

# calculate principal coordinates analysis (Bray-Curtis)
pcoa.U_sorbed_JA_SCH_USCH.bray <- cmdscale(U_sorbed_JA_SCH_USCH.bray, k = 2, eig = T)

# extract axis positions for each site from cmdscale object and create a dataframe for plotting
pcoa.U_sorbed_JA_SCH_USCH.bray.plotting <- as.data.frame(pcoa.U_sorbed_JA_SCH_USCH.bray$points)
colnames(pcoa.U_sorbed_JA_SCH_USCH.bray.plotting) <- c("axis_1", "axis_2")
pcoa.U_sorbed_JA_SCH_USCH.bray.plotting$site <- rownames(pcoa.U_sorbed_JA_SCH_USCH.bray.plotting)

pcoa.U_sorbed_JA_SCH_USCH.bray.plotting <- cbind(pcoa.U_sorbed_JA_SCH_USCH.bray.plotting, samples_nmds)
#%>%select (axis_1, axis_2, pH, iron_total, Fe_HCL_soluble, Sulfur_total, S_HCL_Soluble, LOI)

# calculate the proportion of variance in the data which is explained by the first two PCoA axes
pcoa.U_sorbed_JA_SCH_USCH.bray$eig[1]/(sum(pcoa.U_sorbed_JA_SCH_USCH.bray$eig))
# resulting value is the Xlab 
```
```{r}
pcoa.U_sorbed_JA_SCH_USCH.bray$eig[2]/(sum(pcoa.U_sorbed_JA_SCH_USCH.bray$eig))
#resulting value is the ylab 
```
```{r}
# create a PCoA plot
pcoa.U_sorbed_JA_SCH_USCH.bray.plot <- ggplot(pcoa.U_sorbed_JA_SCH_USCH.bray.plotting, aes(x = axis_1, y = axis_2)) +
  geom_point(aes(colour = days, shape = test), size= 1.5) +
  #geom_text_repel(aes(label = N_to_S_Site_names, element_text = 5),
   #               max.overlaps = Inf,
    #              min.segment.length = 0,
     #             box.padding   = 0.35,
      #            point.padding = 0.5,
       #           segment.color = 'grey50') +
   scale_color_manual(values = myColors) +
  theme_bw() + 
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),)+
    labs(title = "Beta Diversity")+
    xlab("PCA 1 (35.8%)") +
    ylab("PCA 2 (17.8%)") +
    annotate(geom = 'text', label = 'Bray-Curtis', x = -.35, y = .45, hjust = .8, vjust = -1)

plot(pcoa.U_sorbed_JA_SCH_USCH.bray.plot)
```

```{r}
ggsave("figures/Figure_1_nmds_no_normalization_USCH.pdf")
```



```{r}
alpha$days <- factor(alpha$days, levels = c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))

plot.shan <- ggplot(alpha, aes(
  x = fct_relevel(days, c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C")), 
  y = as.numeric(shannon))) +
  geom_boxplot(aes(fill = days), alpha = 0.5) +
  scale_fill_manual(values = myColors) +
  labs(title = "Shannon's H'")+
  ylab("") + 
  xlab("") +
  theme_bw() +
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),
        axis.text.x = element_text(angle = 90, hjust = .5, vjust = 1))

plot.rich <-ggplot(alpha, aes(
  x = fct_relevel(days, c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C")), 
  y = as.numeric(richness))) +
  geom_boxplot(aes(fill = days), alpha = 0.5) +
  scale_fill_manual(values = myColors) +
  labs( title = "Species Richness")+
  ylab("") +
  xlab("") +
  theme_bw() +
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),
        axis.text.x = element_text(angle = 90, hjust = .5, vjust = 1))

plot.even <- ggplot(alpha, aes(
  x = fct_relevel(days, c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C")), 
  y = as.numeric(pielou))) +
  geom_boxplot(aes(fill = days), alpha = 0.5) +
  scale_fill_manual(values = myColors) +
  labs(title = "Pielou's Evenness")+
  ylab("") +
  xlab("") +
  theme_bw() +
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),
        axis.text.x = element_text(angle = 90, hjust = .5, vjust = 1))



ggarrange (plot.shan ,
             plot.rich , 
             plot.even , 
           common.legend = TRUE,
           legend = "bottom",
           nrow= 1)



```

```{r}
ggsave("figures/Figure_1_U_sorbed_JA_SCH_diversity_plots_USCH.pdf", width = 18, height = 10, units = "cm")
```

```{r}
diversity_plots<- grid.arrange (pcoa.U_sorbed_JA_SCH_USCH.bray.plot + theme(legend.position = 'bottom'),
              arrangeGrob(plot.shan + theme(legend.position = "none"),
                          plot.rich + theme(legend.position = "none"), 
                          plot.even + theme(legend.position = "none"),
                          nrow= 1),
              nrow = 1)
```
```{r}
ggsave("figures/Figure_1_U_sorbed_JA_SCH_NMDS_and_diversity_plots_USCH.pdf",diversity_plots, width = 18, height = 10, units = "cm")
```

###Diversity stats USCH

```{r, div stats, regions by USCH }
pdf("Figures/diversity_indicies_tukey_tests_USCH.pdf", width = 8.5, height = 11, onefile = TRUE)
    
alpha_USCH <- alpha

shannon_anova_USCH <- aov(shannon ~ days , data = alpha_USCH)
richness_anova_USCH <- aov( richness ~ days , data = alpha_USCH)
pielou_anova_USCH <- aov(pielou ~ days , data = alpha_USCH)

shannon_tukey_USCH <- shannon_anova_USCH %>% TukeyHSD()
richness_tukey_USCH <- richness_anova_USCH %>% TukeyHSD()
pielou_tukey_USCH <- pielou_anova_USCH %>% TukeyHSD()



summary(shannon_anova_USCH)
print(shannon_tukey_USCH)

summary(richness_anova_USCH)
print(richness_tukey_USCH)

summary(pielou_anova_USCH)
print(pielou_tukey_USCH)

dev.off()

```



```{r simple NMDS, UJA-LPH}


feature_table_UJA_LPH <- read_csv("U_sorbed_JA_SCH_ASV_table.csv",
  col_types = cols(.default = col_double(), seqid = col_character()))
feature_table_UJA_LPH <- feature_table_UJA_LPH[ , -c(2:31)]

T_otu_mat <- feature_table_UJA_LPH %>% tibble::column_to_rownames("seqid") %>% as.matrix() %>% t()


tax_mat <- taxonomy_UJA_LPH %>% tibble::column_to_rownames("seqid") %>% as.matrix()

samples_nmds <- samples_UJA_LPH_grouped %>% tibble::column_to_rownames("sample")%>% as.matrix()
  

# Shannon's H' library(vegan)
H<-diversity(T_otu_mat)

# Observed Richness
richness<-specnumber(T_otu_mat)

# Pielou's Evenness
evenness<- H/log(richness)

# Create alpha diversity dataframe including environmental data pH + iron_total + Fe_HCL_soluble + Sulfur_total + S_HCL_Soluble
alpha <- cbind(shannon = H, richness = richness, pielou = evenness, samples_nmds) 

alpha<-data.frame(sample= row.names(alpha), alpha)

head(alpha)

repl_U_sorbed_JA_SCH_UJA_LPH.mdf<- T_otu_mat

U_sorbed_JA_SCH_UJA_LPH.bray<- vegdist(repl_U_sorbed_JA_SCH_UJA_LPH.mdf, method = "bray")

U_sorbed_JA_SCH_UJA_LPH.bray

U_sorbed_JA_SCH_UJA_LPH.jac <- vegdist(repl_U_sorbed_JA_SCH_UJA_LPH.mdf, method = "jaccard" , binary = T)

U_sorbed_JA_SCH_UJA_LPH.jac

###PCOA

# calculate principal coordinates analysis (Bray-Curtis)
pcoa.U_sorbed_JA_SCH_UJA_LPH.bray <- cmdscale(U_sorbed_JA_SCH_UJA_LPH.bray, k = 2, eig = T)

# extract axis positions for each site from cmdscale object and create a dataframe for plotting
pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting <- as.data.frame(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray$points)
colnames(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting) <- c("axis_1", "axis_2")
pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting$site <- rownames(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting)

pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting <- cbind(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting, samples_nmds)


# calculate the proportion of variance in the data which is explained by the first two PCoA axes
pcoa.U_sorbed_JA_SCH_UJA_LPH.bray$eig[1]/(sum(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray$eig))
# resulting value is the Xlab 
```
```{r}
pcoa.U_sorbed_JA_SCH_UJA_LPH.bray$eig[2]/(sum(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray$eig))
#resulting value is the ylab 
```
```{r}
# create a PCoA plot
pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plot <- ggplot(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plotting, aes(x = axis_1, y = axis_2)) +
  geom_point(aes(colour = days, shape = test), size= 1.5) +
  #geom_text_repel(aes(label = N_to_S_Site_names, element_text = 5),
   #               max.overlaps = Inf,
    #              min.segment.length = 0,
     #             box.padding   = 0.35,
      #            point.padding = 0.5,
       #           segment.color = 'grey50') +
   scale_color_manual(values = myColors) +
  theme_bw() + 
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),)+
    labs(title = "Beta Diversity")+
    xlab("PCA 1 (27.1%)") +
    ylab("PCA 2 (18.3%)") +
    annotate(geom = 'text', label = 'Bray-Curtis', x = -.35, y = .45, hjust = .8, vjust = -1)

plot(pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plot)
```

```{r}
ggsave("figures/Figure_1_nmds_no_normalization_UJA_LPH.pdf")
```

```{r}
alpha$days <- factor(alpha$days, levels = c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C"))
```




```{r}
plot.shan <- ggplot(alpha, aes(
  x = fct_relevel(days,c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C")), 
  y = as.numeric(shannon))) +
  geom_boxplot(aes(fill = days), alpha = 0.5) +
  #geom_point(size = 1.5) +
  scale_fill_manual(values = myColors) +
  labs(title = "Shannon's H'")+
  ylab("") + 
  xlab("") +
  theme_bw() +
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),
        axis.text.x = element_text(angle = 90, hjust = .5, vjust = 1))

plot.rich <-ggplot(alpha, aes(
  x = fct_relevel(days,c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C")),
  y = as.numeric(richness))) +
  geom_boxplot(aes(fill = days), alpha = 0.5) +
  #geom_point(size = 1.5) +
  scale_fill_manual(values = myColors) +
  labs( title = "Species Richness")+
  ylab("") +
  xlab("") +
  theme_bw() +
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),
        axis.text.x = element_text(angle = 90, hjust = .5, vjust = 1))

plot.even <- ggplot(alpha, aes(
  x = fct_relevel(days,c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C")), 
  y = as.numeric(pielou))) +
  geom_boxplot(aes(fill = days), alpha = 0.5) +
  scale_fill_manual(values = myColors) +
  labs(title = "Pielou's Evenness")+
  ylab("") +
  xlab("") +
  theme_bw() +
  theme(plot.title =element_text(size= 5),
        axis.text = element_text(size= 5),
        axis.text.x = element_text(angle = 90, hjust = .5, vjust = 1))


ggarrange (plot.shan ,
             plot.rich , 
             plot.even , 
           common.legend = TRUE,
           legend = "bottom",
           nrow= 1)



```

```{r}
ggsave("figures/Figure_1_U_sorbed_JA_SCH_diversity_plots_UJA_LPH.pdf", width = 18, height = 10, units = "cm")
```


```{r}
diversity_plots<- grid.arrange (pcoa.U_sorbed_JA_SCH_UJA_LPH.bray.plot + theme(legend.position = 'bottom'),
              arrangeGrob(plot.shan + theme(legend.position = "none"),
                          plot.rich + theme(legend.position = "none"), 
                          plot.even + theme(legend.position = "none"),
                          nrow= 1),
              nrow = 1)
```
```{r}
ggsave("figures/Figure_1_U_sorbed_JA_SCH_NMDS_and_diversity_plots_UJA_LPH.pdf",diversity_plots, width = 18, height = 10, units = "cm")
```



##Diversity Statistics UJA_LPH



```{r, div stats, regions by UJA_LPH }
alpha_UJA_LPH <- alpha

shannon_anova_UJA_LPH <- aov(shannon ~ days , data = alpha_UJA_LPH)
richness_anova_UJA_LPH <- aov( richness ~ days , data = alpha_UJA_LPH)
pielou_anova_UJA_LPH <- aov(pielou ~ days , data = alpha_UJA_LPH)

shannon_tukey_UJA_LPH <- shannon_anova_UJA_LPH %>% TukeyHSD()
richness_tukey_UJA_LPH <- richness_anova_UJA_LPH %>% TukeyHSD()
pielou_tukey_UJA_LPH <- pielou_anova_UJA_LPH %>% TukeyHSD()


summary(shannon_anova_UJA_LPH)
print(shannon_tukey_UJA_LPH)
summary(richness_anova_UJA_LPH)
print(richness_tukey_UJA_LPH)
summary(pielou_anova_UJA_LPH)
print(pielou_tukey_UJA_LPH)

```


### CLR and HEL normalization, and RDA



###reset the ASVS files 
```{r read-counts-data }
asvs <- read_csv("U_sorbed_JA_SCH_ASV_table.csv",
  col_types = cols(.default = col_double(), seqid = col_character())) %>%
  gather(sample, count, 2:60) %>%
  # Take away rows with zero count
  filter(count > 0) %>%
  # Take away samples with less than 500 observations (this is an arbitrary choice 
  # to get rid of samples with very low sequencing depth). 
    #due to low seq depth, samples with less than 500 obsv were not filtered
  #group_by(sample) %>% 
  #filter(sum(count) >= 500) %>% 
  ungroup()
```

## Calculate CLR

We want to have a new column called `clr` in the asvs table.



```{r calc-clr, this takes a while}
# This *adds a clr column* to the asvs table.
# Note that the assignment to "asvs" is last and uses the -> assignment operator.  
# Since all combinations of sample and seqid will now get a value, clr, the number of rows
# increases quite a lot.
asvs %>%
  # Make the table wide with samples as columns
  spread(sample, count, fill = 0) %>%
  # Move the seqid to rowname; this requires a data.frame()
  data.frame() %>% tibble::column_to_rownames('seqid') %>%
  # Replace zeroes with probabilities (pseudocounts) (I needed a slightly lower delta than default
  # not to get negative values) thus CZM in original script. what about geometric bayseian multiplicative(GBM)
  cmultRepl(method = 'CZM', delta = 0.5, output = 'p-counts') %>%
  # Calculate the CLR
  codaSeq.clr(samples.by.row = FALSE) %>%
  data.frame() %>%
  tibble::rownames_to_column('sample') %>%
  gather(seqid, clr, 2:ncol(.)) %>%
  # Get rid of 'X' that sometimes precedes the seqid and join back with original table
  mutate(seqid = sub('^X', '', seqid)) %>%
  left_join(asvs, by = c('sample', 'seqid')) %>%
  # Set count to 0 if it's NA
  replace_na(list(count = 0)) ->asvs_CLR
colnames(asvs_CLR)[2] <- "asv"
colnames(asvs_CLR)[1] <- "seqid"
colnames(asvs_CLR)[2] <- "sample"

```


## Redundancy analysis

Redundancy analysis (RDA) is an ordination method that can be constrained by sample metadata or not.
In the latter case, it is identical to principle component analysis (PCA). The fact that we with
clrs have data that is behaving nicely in statistical terms, allowing e.g. euclidian distances to be
measured, makes it possible for us to us this very powerful methodology.

We start by looking at how PCA works, i.e. only studying the distribution of samples and taxa, using
the Vegan package's `rda` function.

```{r calc-pca}
asvs_CLR %>% 
  # Standard Vegan transformation: Turn table with with samples as *rows*
  dplyr::select(sample, seqid, clr) %>%
  spread(seqid, clr) %>%
  # Turn into a numeric matrix
  tibble::column_to_rownames('sample') %>% as.matrix() %>%
  # And call Vegan's rda function that will just do pca unless you give it a 
  # a second argument (constraining matrix)
  vegan::rda() -> pca
```

What's returned by the `rda` funtion is a list object that can be plotted with the base `plot`
function, but we can also pick out the necessary parts to make a PCA *biplot* of samples and ASVs
using `ggplot2`.

```{r pca-biplot, fig.height = 6, fig.cap = 'PCA of the samples. Coloured circles are the samples, and black dots the ASVs positions in the PCA coordinate system.'}
pca.samples <- pca$CA$u %>% data.frame() %>% tibble::rownames_to_column('sample')
pca.asvs    <- pca$CA$v %>% data.frame() %>% tibble::rownames_to_column('seqid')
pca.eigs    <- pca$CA$eig %>% data.frame() %>% tibble::rownames_to_column('pc') 
  colnames(pca.eigs)[2] <- "eigval" 
pca.eigs <- pca.eigs %>% mutate(propexpl = eigval/sum(eigval))
# We use the pca.samples table as the "main" table when calling ggplot.
# Let's first join it with the samples table so we can use some metadata
# for colouring.
pca.samples %>%
  inner_join(samples, by = 'sample')%>%
  ggplot(aes(x = PC1, y = PC2)) +
    # Plot the ASVs *behind* the samples, i.e. first
    geom_point(data = pca.asvs, size = .1) +
    # Points for samples, colored by site names, shape by zone
    geom_point(aes(color = days , shape = coprecipitant)) +
  geom_text_repel(aes(label = new_names, element_text = 5),
                  max.overlaps = Inf,
                  min.segment.length = 0,
                  box.padding   = 0.35,
                  point.padding = 0.5,
                  segment.color = 'grey50') +
    scale_color_manual(values = myColors, breaks = c("9" , "12" , "16" , "22" , "37" , "40" , "83" , "180")) +
    xlab(sprintf("PC1 (%2.1f%% explained)", pca.eigs[1,3] * 100)) +
    ylab(sprintf("PC2 (%2.1f%% explained)", pca.eigs[2,3] * 100)) 
```

## Proper RDA with sample data, using CLR data

Below, I'm selecting three variables from the metadata, average soil relative humidity, average soil
temperature (both continuous) and vegetation (categorical, i.e. yes or no).


```{r calc-rda-2vars}
# Create a matrix object; we need it named, can't generate one on "the fly"
asvs_CLR %>% dplyr::select(sample, seqid, clr) %>%
  spread(seqid, clr) %>% tibble::column_to_rownames('sample') -> asv_matrix
# Here's the call to the rda function with a formula as the first argument,
vegan::rda(
  asv_matrix ~ pH + Fe2_mgL + FeTot_mgL + S_mgL + U_mgL + P_mgL + Ca_mgL + K_mgL + Mg_mgL + Na_mgL + Si_mgL, data = samples %>%
    semi_join(asvs, by = 'sample') %>%
    #replace_na(list('LOI' = 0.01)) %>%
    tibble::column_to_rownames('sample')
) -> rda

```

The results of an RDA analysis can be plotted as a *triplot* with arrows pointing in the direction
of the environmental parameters (`r figr('rda-triplot', T, type = 'Figure')`). (Usually categorical
variables are plotted as points and not as arrows as in my figure.)

```{r rda-triplot, fig.height = 6, fig.cap = 'Redundancy analysis (RDA). Samples are plotted together with vectors indicating the influence of the three factors included in the analysis. *Note 1*: Many samples got the same coordinates, and are hence plotted on top of each other. *Note 2*: that the lengths of the factor vectors were divided by four to fit inside the plot. They should hence only be interpreted as directions.'}
# I need to collect some temporary data sets for the plot
# This one will contain the proportions explained which we get by dividing the
# eigenvalue of each component with the sum of eigenvalues for all components.
p <- c(rda$CCA$eig, rda$CA$eig)/sum(c(rda$CCA$eig, rda$CA$eig))

# This one is collecting the coordinates for arrows that will depict how the 
# factors in our model point in the coordinate
a <- rda$CCA$biplot %>% data.frame() %>% tibble::rownames_to_column('factor')

rda$CCA$u %>% data.frame() %>% tibble::rownames_to_column('sample') %>%
  inner_join(samples, by = 'sample') %>%
  ggplot(aes(x = RDA1, y = RDA2)) +
     geom_point(aes(colour = days , shape = coprecipitant)) +
 # geom_text_repel(aes(label = N_to_S_Site_names, element_text = 5),
  #                max.overlaps = Inf,
   #               min.segment.length = 0,
    #              box.padding   = 0.35,
     #             point.padding = 0.5,
      #            segment.color = 'grey50') +
    scale_color_manual(values = myColors, breaks = c("9" , "12" , "16" , "22" , "37" , "40" , "83" , "180")) +
    xlab(sprintf("RDA1 (%2.1f%% explained)", p[[1]] * 100)) +
    ylab(sprintf("RDA2 (%2.1f%% explained)", p[[2]] * 100)) +
   
    geom_segment(
      data = a, mapping = aes(xend = RDA1, yend = RDA2), 
      x = 0, y = 0, arrow = arrow()
    ) +
    # Print the names of factors halfway along the arrows
    geom_text(
      data = a, mapping = aes(x = RDA1, y = RDA2, label = factor), 
      size = 5)
  
```

```{r}
ggsave("figures/RDA_CLR_ENV_USCH+UJA_LPH.pdf", width = 18, height = 10, units = "cm")
```


## Calculate hellinger

We want to have a new column called `hel` in the asvs table but the ASVS table need to be renewed following use with the HEL RDA.

```{r calc-hel, this takes a while}
# This *adds a hel column* to the asvs table.
# Note that the assignment to "asvs" is last and uses the -> assignment operator.  
# Since all combinations of sample and seqid will now get a value, hel, the number of rows
# increases quite a lot.
asvs_HEL <- asvs %>%
  # Make the table wide with samples as columns
  spread(sample, count, fill = 0) %>%
  # Move the seqid to rowname; this requires a data.frame()
  data.frame() %>% tibble::column_to_rownames('seqid')%>%
  # Replace zeroes with probabilities (pseudocounts) (I needed a slightly lower delta than default
  # not to get negative values) thus CZM in original script. what about geometric bayseian multiplicative(GBM)
   cmultRepl(method = 'CZM', delta = 0.5, output = 'p-counts')%>%
  # Calculate the hel
  decostand(method = "hellinger") %>%
  data.frame() %>%
  tibble::rownames_to_column('sample')%>%
  gather(seqid, hel, 2:ncol(.)) %>%
  # Get rid of 'X' that sometimes precedes the seqid and join back with original table
  mutate(seqid = sub('^X', '', seqid)) %>%
  left_join(asvs, by = c('sample', 'seqid')) %>%
  # Set count to 0 if it's NA
  replace_na(list(count = 0))

  colnames(asvs_HEL)[2] <- "asv"
  colnames(asvs_HEL)[1] <- "seqid"
  colnames(asvs_HEL)[2] <- "sample"
```

```{r calc-pca}
asvs_HEL %>% 
  # Standard Vegan transformation: Turn table with with samples as *rows*
  dplyr::select(sample, seqid, hel) %>%
  spread(seqid, hel) %>%
  # Turn into a numeric matrix
  tibble::column_to_rownames('sample') %>% as.matrix() %>%
  # And call Vegan's rda function that will just do pca unless you give it a 
  # a second argument (constraining matrix)
  vegan::rda() -> pca
```

What's returned by the `rda` funtion is a list object that can be plotted with the base `plot`
function, but we can also pick out the necessary parts to make a PCA *biplot* of samples and ASVs
using `ggplot2`.

```{r pca-biplot, fig.height = 6, fig.cap = 'PCA of the samples. Coloured circles are the samples, and black dots the ASVs positions in the PCA coordinate system.'}
pca.samples <- pca$CA$u %>% data.frame() %>% tibble::rownames_to_column('sample')
pca.asvs    <- pca$CA$v %>% data.frame() %>% tibble::rownames_to_column('seqid')
pca.eigs    <- pca$CA$eig %>% data.frame() %>% tibble::rownames_to_column('pc') 
  colnames(pca.eigs)[2] <- "eigval" 
pca.eigs <- pca.eigs %>% mutate(propexpl = eigval/sum(eigval))
# We use the pca.samples table as the "main" table when calling ggplot.
# Let's first join it with the samples table so we can use some metadata
# for colouring.
pca.samples %>%
  inner_join(samples, by = 'sample')%>%
  ggplot(aes(x = PC1, y = PC2)) +
    # Plot the ASVs *behind* the samples, i.e. first
    geom_point(data = pca.asvs, size = .1) +
    # Points for samples, coloured by site names, shape by zone
    geom_point(aes(colour = days , shape = coprecipitant)) +
  geom_text_repel(aes(label = new_names, element_text = 5),
                  max.overlaps = Inf,
                  min.segment.length = 0,
                  box.padding   = 0.35,
                  point.padding = 0.5,
                  segment.color = 'grey50') +
    scale_color_manual(values = myColors, breaks = c("9" , "12" , "16" , "22" , "37" , "40" , "83" , "180")) +
    xlab(sprintf("PC1 (%2.1f%% explained)", pca.eigs[1,3] * 100)) +
    ylab(sprintf("PC2 (%2.1f%% explained)", pca.eigs[2,3] * 100)) 
```


## Proper RDA with sample data, using HEL data

Below, I'm selecting three variables from the metadata, average soil relative humidity, average soil
temperature (both continuous) and vegetation (categorical, i.e. yes or no).


```{r calc-rda-2vars}
# Create a matrix object; we need it named, can't generate one on "the fly"
asvs_HEL %>% dplyr::select(sample, seqid, hel) %>%
  spread(seqid, hel) %>% tibble::column_to_rownames('sample') -> asv_matrix
# Here's the call to the rda function with a formula as the first argument,
vegan::rda(
  asv_matrix ~ pH + Fe2_mgL + FeTot_mgL + S_mgL + U_mgL + P_mgL + Ca_mgL + K_mgL + Mg_mgL + Na_mgL + Si_mgL, data = samples %>%
    semi_join(asvs, by = 'sample') %>%
    #replace_na(list('LOI' = 0.01)) %>%
    tibble::column_to_rownames('sample')
) -> rda

```

The results of an RDA analysis can be plotted as a *triplot* with arrows pointing in the direction
of the environmental parameters (`r figr('rda-triplot', T, type = 'Figure')`). (Usually categorical
variables are plotted as points and not as arrows as in my figure.)

```{r rda-triplot, fig.height = 6, fig.cap = 'Redundancy analysis (RDA). Samples are plotted together with vectors indicating the influence of the three factors included in the analysis. *Note 1*: Many samples got the same coordinates, and are hence plotted on top of each other. *Note 2*: that the lengths of the factor vectors were divided by four to fit inside the plot. They should hence only be interpreted as directions.'}
# I need to collect some temporary data sets for the plot
# This one will contain the proportions explained which we get by dividing the
# eigenvalue of each component with the sum of eigenvalues for all components.
p <- c(rda$CCA$eig, rda$CA$eig)/sum(c(rda$CCA$eig, rda$CA$eig))

# This one is collecting the coordinates for arrows that will depict how the 
# factors in our model point in the coordinate
a <- rda$CCA$biplot %>% data.frame() %>% tibble::rownames_to_column('factor')

rda$CCA$u %>% data.frame() %>% tibble::rownames_to_column('sample') %>%
  inner_join(samples, by = 'sample') %>%
  ggplot(aes(x = RDA1, y = RDA2)) +
     geom_point(aes(colour = days , shape = coprecipitant)) +
  #geom_text_repel(aes(label = N_to_S_Site_names, element_text = 5),
   #               max.overlaps = Inf,
    #              min.segment.length = 0,
     #             box.padding   = 0.35,
      #            point.padding = 0.5,
       #           segment.color = 'grey50') +
    scale_color_manual(values = myColors, breaks = c("9" , "12" , "16" , "22" , "37" , "40" , "83" , "180")) +
    xlab(sprintf("RDA1 (%2.1f%% explained)", p[[1]] * 100)) +
    ylab(sprintf("RDA2 (%2.1f%% explained)", p[[2]] * 100)) +
    
    geom_segment(
      data = a, mapping = aes(xend = RDA1/4, yend = RDA2/4), 
      x = 0, y = 0, arrow = arrow()
    ) +
    # Print the names of factors halfway along the arrows
    geom_text(
      data = a, mapping = aes(x = RDA1/8, y = RDA2/8, label = factor), 
      size = 3)
  
```
```{r}
ggsave("figures/Figure_2_RDA_HEL_ENV.pdf", width = 18, height = 10, units = "cm")
```


### recalculate seperately USCH 


```{r}
asvs_USCH <- asvs %>% 
  merge(samples) 

asvs_USCH <- subset(asvs_USCH, coprecipitant == "USCH") %>%
  subset(select = c(seqid, sample, count))

samples_USCH <- subset( samples, coprecipitant == "USCH")
```





```{r calc-hel, this takes a while}
# This *adds a hel column* to the asvs table.
# Note that the assignment to "asvs" is last and uses the -> assignment operator.  
# Since all combinations of sample and seqid will now get a value, hel, the number of rows
# increases quite a lot.
asvs_HEL_USCH <- asvs_USCH %>%
  # Make the table wide with samples as columns
  spread(sample, count, fill = 0) %>%
  # Move the seqid to rowname; this requires a data.frame()
  data.frame() %>% tibble::column_to_rownames('seqid')%>%
 
  cmultRepl(method = 'CZM', delta = 0.5, output = 'p-counts')%>%
  # Calculate the hel
  decostand(method = "hellinger") %>%
  data.frame() %>%
  tibble::rownames_to_column('sample') %>%
  gather(seqid, hel, 2:ncol(.)) %>%
  # Get rid of 'X' that sometimes precedes the seqid and join back with original table
  mutate(seqid = sub('^X', '', seqid)) %>%
  left_join(asvs, by = c('sample', 'seqid')) %>%
  # Set count to 0 if it's NA
  replace_na(list(count = 0)) 
   
   colnames(asvs_HEL_USCH)[2] <- "asv"
  colnames(asvs_HEL_USCH)[1] <- "seqid"
  colnames(asvs_HEL_USCH)[2] <- "sample"
  
```



## Proper RDA with sample data, using HEL data

Below, I'm selecting three variables from the metadata, average soil relative humidity, average soil
temperature (both continuous) and vegetation (categorical, i.e. yes or no).


```{r calc-rda-2vars}
# Create a matrix object; we need it named, can't generate one on "the fly"
asvs_HEL_USCH %>% dplyr::select(sample, seqid, hel) %>%
  spread(seqid, hel) %>% tibble::column_to_rownames('sample') -> asv_matrix_USCH
# Here's the call to the rda function with a formula as the first argument,
vegan::rda(
  asv_matrix_USCH ~ pH + Fe2_mgL + FeTot_mgL + S_mgL + U_mgL + P_mgL + Ca_mgL + K_mgL + Mg_mgL + Na_mgL + Si_mgL, data = samples_USCH %>%
    semi_join(asvs, by = 'sample') %>%
    #replace_na(list('LOI' = 0.01)) %>%
    tibble::column_to_rownames('sample')
) -> rda_HEL_USCH

```

The results of an RDA analysis can be plotted as a *triplot* with arrows pointing in the direction
of the environmental parameters (`r figr('rda-triplot', T, type = 'Figure')`). (Usually categorical
variables are plotted as points and not as arrows as in my figure.)

```{r rda-triplot, fig.height = 6, fig.cap = 'Redundancy analysis (RDA). Samples are plotted together with vectors indicating the influence of the three factors included in the analysis. *Note 1*: Many samples got the same coordinates, and are hence plotted on top of each other. *Note 2*: that the lengths of the factor vectors were divided by four to fit inside the plot. They should hence only be interpreted as directions.'}
# I need to collect some temporary data sets for the plot
# This one will contain the proportions explained which we get by dividing the
# eigenvalue of each component with the sum of eigenvalues for all components.
p<- c(rda_HEL_USCH$CCA$eig, rda_HEL_USCH$CA$eig)/sum(c(rda_HEL_USCH$CCA$eig, rda_HEL_USCH$CA$eig))

# This one is collecting the coordinates for arrows that will depict how the 
# factors in our model point in the coordinate
a<- rda_HEL_USCH$CCA$biplot %>% data.frame() %>% tibble::rownames_to_column('factor')

rda_HEL_USCH$CCA$u %>% data.frame() %>% tibble::rownames_to_column('sample') %>%
  inner_join(samples_USCH, by = 'sample') %>%
  mutate(test = factor(test)) %>%  # Convert 'test' to a factor
  ggplot(aes(x = RDA1, y = RDA2)) +
     geom_point(aes(colour = days , shape = test)) +
  #geom_text_repel(aes(label = N_to_S_Site_names, element_text = 5),
   #               max.overlaps = Inf,
    #              min.segment.length = 0,
     #             box.padding   = 0.35,
      #            point.padding = 0.5,
       #           segment.color = 'grey50') +
    scale_color_manual(values = myColors, breaks = c("9" , "12", "16" , "22" , "37" , "37C" , "40" , "83" , "180" , "180C"))  + 
    xlab(sprintf("RDA1 (%2.1f%% explained)", p[[1]] * 100)) +
    ylab(sprintf("RDA2 (%2.1f%% explained)", p[[2]] * 100)) +
    
    geom_segment(
      data = a, mapping = aes(xend = RDA1, yend = RDA2), 
      x = 0, y = 0, arrow = arrow()
    ) +
    # Print the names of factors halfway along the arrows
    geom_text(
      data = a, mapping = aes(x = RDA1, y = RDA2, label = factor), 
      size = 3)
  
```

```{r}
ggsave("figures/Figure_2_RDA_HEL_ENV_USCH.pdf", width = 18, height = 10, units = "cm")
```


### recalculate seperately UJA_LPH 


```{r}
asvs_UJA_LPH <- asvs %>% 
  merge(samples) 

asvs_UJA_LPH <- subset(asvs_UJA_LPH, coprecipitant == "UJA-LPH") %>%
  subset(select = c(seqid, sample, count))

samples_UJA_LPH <- subset( samples, coprecipitant == "UJA-LPH")
```





```{r calc-hel, this takes a while}
# This *adds a hel column* to the asvs table.
# Note that the assignment to "asvs" is last and uses the -> assignment operator.  
# Since all combinations of sample and seqid will now get a value, hel, the number of rows
# increases quite a lot.
asvs_HEL_UJA_LPH <- asvs_UJA_LPH %>%
  # Make the table wide with samples as columns
  spread(sample, count, fill = 0) %>%
  # Move the seqid to rowname; this requires a data.frame()
  data.frame() %>% tibble::column_to_rownames('seqid')%>%
 
  cmultRepl(method = 'CZM', delta = 0.5, output = 'p-counts')%>%
  # Calculate the hel
  decostand(method = "hellinger") %>%
  data.frame() %>%
  tibble::rownames_to_column('sample') %>%
  gather(seqid, hel, 2:ncol(.)) %>%
  # Get rid of 'X' that sometimes precedes the seqid and join back with original table
  mutate(seqid = sub('^X', '', seqid)) %>%
  left_join(asvs, by = c('sample', 'seqid')) %>%
  # Set count to 0 if it's NA
  replace_na(list(count = 0)) 
   
   colnames(asvs_HEL_UJA_LPH)[2] <- "asv"
  colnames(asvs_HEL_UJA_LPH)[1] <- "seqid"
  colnames(asvs_HEL_UJA_LPH)[2] <- "sample"
  
```



## Proper RDA with sample data, using HEL data

Below, I'm selecting three variables from the metadata, average soil relative humidity, average soil
temperature (both continuous) and vegetation (categorical, i.e. yes or no).


```{r calc-rda-2vars}
# Create a matrix object; we need it named, can't generate one on "the fly"
asvs_HEL_UJA_LPH %>% dplyr::select(sample, seqid, hel) %>%
  spread(seqid, hel) %>% tibble::column_to_rownames('sample') -> asv_matrix_UJA_LPH
# Here's the call to the rda function with a formula as the first argument,
vegan::rda(
  asv_matrix_UJA_LPH ~ pH + Fe2_mgL + FeTot_mgL + S_mgL + U_mgL + P_mgL + Ca_mgL + K_mgL + Mg_mgL + Na_mgL + Si_mgL, data = samples_UJA_LPH %>%
    semi_join(asvs, by = 'sample') %>%
    #replace_na(list('LOI' = 0.01)) %>%
    tibble::column_to_rownames('sample')
) -> rda_HEL_UJA_LPH

```

The results of an RDA analysis can be plotted as a *triplot* with arrows pointing in the direction
of the environmental parameters (`r figr('rda-triplot', T, type = 'Figure')`). (Usually categorical
variables are plotted as points and not as arrows as in my figure.)

```{r rda-triplot, fig.height = 6, fig.cap = 'Redundancy analysis (RDA). Samples are plotted together with vectors indicating the influence of the three factors included in the analysis. *Note 1*: Many samples got the same coordinates, and are hence plotted on top of each other. *Note 2*: that the lengths of the factor vectors were divided by four to fit inside the plot. They should hence only be interpreted as directions.'}
# I need to collect some temporary data sets for the plot
# This one will contain the proportions explained which we get by dividing the
# eigenvalue of each component with the sum of eigenvalues for all components.
p<- c(rda_HEL_UJA_LPH$CCA$eig, rda_HEL_UJA_LPH$CA$eig)/sum(c(rda_HEL_UJA_LPH$CCA$eig, rda_HEL_UJA_LPH$CA$eig))

# This one is collecting the coordinates for arrows that will depict how the 
# factors in our model point in the coordinate
a<- rda_HEL_UJA_LPH$CCA$biplot %>% data.frame() %>% tibble::rownames_to_column('factor')

rda_HEL_UJA_LPH$CCA$u %>% data.frame() %>% tibble::rownames_to_column('sample') %>%
  inner_join(samples_UJA_LPH, by = 'sample') %>%
  mutate(test = factor(test)) %>%
  ggplot(aes(x = RDA1, y = RDA2)) +
     geom_point(aes(colour = days , shape = test)) +
  #geom_text_repel(aes(label = N_to_S_Site_names, element_text = 5),
   #               max.overlaps = Inf,
    #              min.segment.length = 0,
     #             box.padding   = 0.35,
      #            point.padding = 0.5,
       #           segment.color = 'grey50') +
    scale_color_manual(values = myColors, breaks = c("9" , "16" , "22" , "58" , "58C" , "80" , "144" , "165" , "180" , "180C")) +
    xlab(sprintf("RDA1 (%2.1f%% explained)", p[[1]] * 100)) +
    ylab(sprintf("RDA2 (%2.1f%% explained)", p[[2]] * 100)) +
    
    geom_segment(
      data = a, mapping = aes(xend = RDA1, yend = RDA2), 
      x = 0, y = 0, arrow = arrow()
    ) +
    # Print the names of factors halfway along the arrows
    geom_text(
      data = a, mapping = aes(x = RDA1, y = RDA2, label = factor), 
      size = 3)
  
```

```{r}
ggsave("figures/Figure_2_RDA_HEL_ENV_UJA_LPH.pdf", width = 18, height = 10, units = "cm")
```















